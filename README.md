# MLOps í”„ë¡œì íŠ¸: ë¹„ì •ì œ í•œêµ­ì–´ ë°ì´í„° ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 í”„ë¡œì íŠ¸ ì •ë³´

- **í”„ë¡œì íŠ¸ ê¸°ê°„**: 2024ë…„ 11ì›” 25ì¼ ~ 12ì›” 6ì¼
- **ëª©í‘œ**:
    - ì›¹ ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ëª¨ë¸ ì„œë¹™ê¹Œì§€ì˜ **End-to-End MLOps íŒŒì´í”„ë¼ì¸ êµ¬í˜„**
    - ì‹¤ì‹œê°„ ê¸ì •/ë¶€ì •ì„ ì˜ˆì¸¡í•˜ëŠ” í•œêµ­ì–´ ê°ì„± ë¶„ì„ ì‹œìŠ¤í…œ ê°œë°œ

### 1.2 Team ML 4 ë©¤ë²„ ë° í˜‘ì—…

- **ë°•ì •ì¤€**:
    - **AI Engineer**
        - **:** NLP ëª¨ë¸ ê°œë°œ, ëª¨ë¸ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ (MLflow)
- **ê¹€ë™ì™„**:
    - **Data Engineer**
        - : Data management & scraping ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬
- **ê¹€ë¬˜ì •**
    - **Front-end Engineer, QA**
        - : í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ (Streamlit), ëª¨ë¸ í…ŒìŠ¤íŠ¸
- **ì´ë‹¤ì–¸**:
    - **Back-end Engineer**
        - : Fast API

### 1.3 MLOps ì•„í‚¤í…ì³ í”Œë¡œìš°ì°¨íŠ¸
![MLOps ì•„í‚¤í…ì³ ì „ì²´ í”Œë¡œìš°ì°¨íŠ¸](https://github.com/UpstageAILab5/upstageailab-ml-pjt-ml_p4/blob/main/assets/images/flowchart_all.png)
![MLOps ì•„í‚¤í…ì³ í”Œë¡œìš°ì°¨íŠ¸](https://github.com/UpstageAILab5/upstageailab-ml-pjt-ml_p4/blob/main/assets/images/flowchart_model.png)
---


## 2. ì£¼ìš” ê¸°ëŠ¥

### 2.1 ë°ì´í„° ìˆ˜ì§‘

- **ì›¹ ë°ì´í„° í¬ë¡¤ë§**: Selenium ë° Scrapy ì‚¬ìš©
- **ì •ì œëœ í…ìŠ¤íŠ¸ ì²˜ë¦¬**: í•œê¸€ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ

### 2.2 ëª¨ë¸ í•™ìŠµ ë° ê´€ë¦¬

- **ëª¨ë¸ ê°œë°œ**:
    - Kc-BERT ë° Kc-ELECTRA ê¸°ë°˜ Fine-tuning
    - NSMC ë°ì´í„°ì…‹ ì‚¬ìš©
- **MLflowë¥¼ í™œìš©í•œ ê´€ë¦¬**:
    - ì‹¤í—˜ ì¶”ì  ë° ëª¨ë¸ ë²„ì „ ê´€ë¦¬

### 2.3 ëª¨ë¸ ì„œë¹™

- **FastAPI**: ì‹¤ì‹œê°„ ê°ì„± ì˜ˆì¸¡ API ì œê³µ
- **Airflow**: ë°°ì¹˜ ì‘ì—… ê´€ë¦¬

### 2.4 í”„ë¡ íŠ¸ì—”ë“œ

- **Streamlit**: ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì§ì ‘ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ ì œê³µ

---

## 3. ë””ë ‰í† ë¦¬ êµ¬ì¡° ë° ì„¤ì •

```plaintext
project_root/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ base_model.py         # Model architecture definitions
â”‚   â”‚   â””â”€â”€ kcbert_model.py       # KcBERT Model architecture definitions
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ visualization.py
â”‚   â”‚   â””â”€â”€ mlflow_utils.py      # MLflow integration utilities
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ base_dataset.py
â”‚       â””â”€â”€ nsmc_dataset.py     # nsmc dataset script
â”œâ”€â”€ â”€â”€  train.py              # train module script
â”‚   â””â”€â”€ inference.py          # inference module script
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml          # Configuration files
â”‚   â””â”€â”€ model_registry.json  # Model registry files
â”œâ”€â”€ mlruns/                  # mlflow artifacts files folder
â”œâ”€â”€ init-scripts/
â”‚   â”œâ”€â”€ init.sh              # Docker init file
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ dags.py             # dags script for airflow
â”œâ”€â”€ app.py                   # streamlit web gui for model test & management
â”œâ”€â”€ requirements.txt 
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml 
â”œâ”€â”€ Dockerfile
â””â”€â”€ .env                     # Environment variables for slack webhook - docker
```

### ğŸ“ src
- ì£¼ìš” ëª¨ë“ˆ ì½”ë“œ ë³´ê´€
  - **config.py**: í”„ë¡œì íŠ¸ ì„¤ì • ê´€ë¦¬
  - **data/**: ë°ì´í„° ê´€ë ¨ ì½”ë“œ
  - **models/**: ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜
  - **utils/**: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ìŒ
### ğŸ“ data
 - raw/: raw data
     - `data, models í´ë” ë° íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ì—ë„ [train.py](http://train.py) ì‹¤í–‰ì‹œ ì €ì ˆë¡œ ë°ì´í„°,ëª¨ë¸ ë‹¤ìš´ë°›ì•„ ì‹¤í–‰`
 - processed/: processed data
### ğŸ“ models
- Pretrained models
### ğŸ“ configs
- YAML ê¸°ë°˜ ì„¤ì • íŒŒì¼
    - **ë°ì´í„°ì…‹ ì¢…ë¥˜**: ì‚¬ìš©í•  ë°ì´í„°ì…‹ ì¢…ë¥˜ ì„¤ì • (ê¸°ë³¸ê°’: NSMC - ë„¤ì´ë²„ ì˜í™” ë¦¬ë·°)
    - **ëª¨ë¸ ì„¤ì •**: ì‚¬ìš©í•  ëª¨ë¸ ë° í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • (ê¸°ë³¸ê°’: KcBERT)
    - **ê¸°íƒ€ íŒŒë¼ë¯¸í„°**:
        - `dataset_sampling_rate`: ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•œ ë°ì´í„°ì…‹ ìƒ˜í”Œë§ ë¹„ìœ¨
        - `max_length`: ëª¨ë¸ ì…ë ¥ì˜ ìµœëŒ€ ê¸¸ì´
        - `register_threshold`: ëª¨ë¸ ë“±ë¡ì„ ìœ„í•œ ìµœì†Œ ê¸°ì¤€
        - `unfrozen_layers`: í•™ìŠµ ì‹œ ì–¸í”„ë¦¬ì¦ˆí•  ë ˆì´ì–´ ìˆ˜
    
    - `requirements.txt`: í”„ë¡œì íŠ¸ ì˜ì¡´ì„±
    - `.env`: í™˜ê²½ ë³€ìˆ˜
    - `README.md`: í”„ë¡œì íŠ¸ ë¬¸ì„œ
- JSON ê¸°ë°˜ Model ê´€ë¦¬ íŒŒì¼
### ğŸ“ mlruns
- MLflow ì‹¤í–‰ ê²°ê³¼ metadata ì €ì¥ í´ë”
### ğŸ“ mlartifacts
- MLflow ì‹¤í–‰ ê²°ê³¼ Model ë“± ì•„í‹°íŒ©íŠ¸ ì €ì¥ í´ë”
---
## 4. ê¸°ìˆ  ìŠ¤íƒ

### 4.1 ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬

- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: Selenium, Scrapy
- **ì •ì œ ì‘ì—…**:
    - HTML íƒœê·¸ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°
    - ì—°ì† ê³µë°± ë° ì´ëª¨ì§€ ì œê±°

### 4.2 NLP ëª¨ë¸

- **ëª¨ë¸**: Kc-BERT, Kc-ELECTRA
- **ë°ì´í„°ì…‹**: NSMC (Naver Sentiment Movie Corpus)
- **ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê¸°ì¤€**: F1 Score â‰¥ 0.7

### 4.3 MLOps

- **MLflow**: ëª¨ë¸ ë²„ì „ ê´€ë¦¬
    - ì‹¤í—˜ ë° ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì 
    - MLflow Model Registry, ë³„ë„ì˜ model_registry.json íŒŒì¼ ì •ë³´ë¥¼ ì‹±í¬, ëª¨ë¸ ë²„ì „ ê´€ë¦¬
    - **ëª¨ë¸ ë‹¨ê³„**:
        - **Candidate**: ìƒˆë¡œ í›ˆë ¨ëœ ëª¨ë¸
        - **Champion**: í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œëœ ëª¨ë¸
        - **Archived**: ì‚¬ìš© ì¤‘ë‹¨ëœ ëª¨ë¸
- **Docker & Airflow**: ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
    - Airflow ì»¨í…Œì´ë„ˆ ìë™ ìƒì„±
    - Slack webhook ì—°ê²° ë° ê³„ì • ìë™ ìƒì„±
      - ëª¨ë¸ ë“±ë¡ ì•Œë¦¼ ë° ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì•Œë¦¼

### 4.4 ëª¨ë¸ ì„œë¹™

- **FastAPI**: ì‹¤ì‹œê°„ ì¶”ë¡  API
- **API ì‘ë‹µ ì˜ˆì‹œ**:
    
    ```json
    {
      "prediction": "positive",
      "confidence": 0.95
    }
    ```
---

## 5. ì‚¬ìš©í•œ ë°ì´í„°ì…‹ ë° ëª¨ë¸

### 5.1 NSMC ë°ì´í„°ì…‹

- **ì¶œì²˜**: [GitHub - e9t/nsmc](https://github.com/e9t/nsmc)
- **ë‚´ìš©**: ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° í…ìŠ¤íŠ¸ì™€ ê°ì„± ë ˆì´ë¸” (ê¸ì •: 1, ë¶€ì •: 0)
- **íŠ¹ì§•**:
    - ì´ 20ë§Œ ê°œì˜ ë°ì´í„° (í›ˆë ¨: 15ë§Œ ê°œ, í…ŒìŠ¤íŠ¸: 5ë§Œ ê°œ)
    - êµ¬ì–´ì²´, ë¹„ì†ì–´, ì˜¤íƒˆì ë“±ì´ í¬í•¨ëœ ì •ì œë˜ì§€ ì•Šì€ ë°ì´í„°
- **ì‚¬ìš© ëª©ì **: í•œêµ­ì–´ ê°ì„± ë¶„ì„ ëª¨ë¸ í•™ìŠµ

### 5.2 Kc-BERT ëª¨ë¸

- **ì¶œì²˜**: [GitHub - Beomi/KcBERT](https://github.com/Beomi/KcBERT)
- **ì•„í‚¤í…ì²˜**: BERT-base
- **í•™ìŠµ ë°ì´í„°**:
    - í•œêµ­ì–´ ìœ„í‚¤ë°±ê³¼
    - ë‰´ìŠ¤ ê¸°ì‚¬
    - ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° ëŒ“ê¸€ ë° SNS ë°ì´í„°
- **íŠ¹ì§•**:
    - êµ¬ì–´ì²´ ë° ë¹„ì •í˜• í‘œí˜„ ì´í•´ì— ê°•ì 
    - ê°ì„± ë¶„ì„, ë¬¸ì„œ ë¶„ë¥˜ ë“± í•œêµ­ì–´ NLP íƒœìŠ¤í¬ì— ì í•©

### 5.3 Kc-ELECTRA ëª¨ë¸

- **ì¶œì²˜**: [GitHub - Beomi/KcBERT](https://github.com/Beomi/KcBERT)
- **ì•„í‚¤í…ì²˜**: ELECTRA-base (Generator-Discriminator)
- **í•™ìŠµ ë°ì´í„°**:
    - í•œêµ­ì–´ ìœ„í‚¤ë°±ê³¼
    - ë‰´ìŠ¤ ê¸°ì‚¬
    - ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° ëŒ“ê¸€ ë° SNS ë°ì´í„°
- **íŠ¹ì§•**:
    - BERT ëŒ€ë¹„ ê²½ëŸ‰í™”
    - ë¹ ë¥¸ í•™ìŠµê³¼ ì¶”ë¡ ì´ í•„ìš”í•œ í™˜ê²½ì—ì„œ ì í•©

---

## 6. ì‹¤í–‰ ê°€ì´ë“œ

### 6.1 í™˜ê²½ ì„¤ì •
- **ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸ í™˜ê²½**
    - Linux, Windows 10, Mac OS
- **Python ë²„ì „**
    - Python 3.10
- **Conda í™˜ê²½ ìƒì„±**:

```bash
conda create -n ml4 python=3.10
conda activate ml4
pip install -r requirements.txt
```

### 6.2 ì„¤ì •
`config/config.yaml` íŒŒì¼ì„ ì—´ì–´ í•„ìš”í•œ ì„¤ì •ì„ í™•ì¸í•˜ê³  ì‹¤í—˜ì— ë§ê²Œ ìˆ˜ì •

- **ë°ì´í„°ì…‹ ì„¤ì •**: `dataset` ì„¹ì…˜ì—ì„œ ë°ì´í„°ì…‹ ì¢…ë¥˜ì™€ ìƒ˜í”Œë§ ë¹„ìœ¨ ë“±ì„ ì„¤ì •
- **ëª¨ë¸ ì„¤ì •**: `model` ì„¹ì…˜ì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ê³¼ í•™ìŠµ íŒŒë¼ë¯¸í„° ë“±ì„ ì„¤ì •
- **í•™ìŠµ ì„¤ì •**: `train` ì„¹ì…˜ì—ì„œ ì—í¬í¬ ìˆ˜, ë°°ì¹˜ í¬ê¸° ë“±ì„ ì„¤ì •
  
### 6.3 MLflow ì„œë²„ ì‹¤í–‰

```bash
mlflow ui --host 127.0.0.1 --port 5050
```

- ë¸Œë¼ìš°ì €ì—ì„œ `http://127.0.0.1:5050`ì— ì ‘ì†

### 6.3 ëª¨ë¸ í•™ìŠµ: train ëª¨ë“ˆ

```bash
python train.py
```
- êµ¬ì¡°
```bash
        Args:
            interactive: ëŒ€í™”í˜• ì¶”ë¡  ë° ëª¨ë¸ ê´€ë¦¬ ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€ (ì˜µì…˜: default = False)
        Returns:
            dict: í•™ìŠµ ê²°ê³¼ ì •ë³´
            {
                'run_id': str,
                'metrics': dict,
                'run_name': str,
                'model': PreTrainedModel,
                'tokenizer': PreTrainedTokenizer,
                'data_module': NSMCDataModule
            }
```
- ì‚¬ìš© ì˜ˆì‹œ
```bash
from src.train import SentimentTrainer
# ê¸°ë³¸ í•™ìŠµ. ì„¤ì •ì€ config.yaml ì—ì„œ project í•­ëª©
trainer = SentimentTrainer()
result = trainer.train()
```
### 6.4 ì¶”ë¡  ëª¨ë“ˆ: inference ëª¨ë“ˆ

**ì¶”ë¡  ì½”ë“œ**:
- êµ¬ì¡°
```bash
        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸ ë˜ëŠ” í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            return_probs: í™•ë¥ ê°’ ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            Dict ë˜ëŠ” Dict ë¦¬ìŠ¤íŠ¸: ì˜ˆì¸¡ ê²°ê³¼
            {
                'text': str,  # ì›ë³¸ í…ìŠ¤íŠ¸
                'label': str,  # 'ê¸ì •' ë˜ëŠ” 'ë¶€ì •'
                'confidence': float,  # ì˜ˆì¸¡ í™•ì‹ ë„
                'probs': {  # ê° ë ˆì´ë¸”ë³„ í™•ë¥  (return_probs=Trueì¸ ê²½ìš°)
                    'ê¸ì •': float,
                    'ë¶€ì •': float
                }
            }
```
- ì‚¬ìš© ì˜ˆì‹œ
```bash
from src.inference import SentimentPredictor
predictor = SentimentPredictor() # default: Production (ìµœì‹  ëª¨ë¸)
texts = ["ë‹¤ì‹œ ë³´ê³  ì‹¶ì€ ì˜í™”", "ë³„ë¡œì—ìš”"]
results = predictor.predict(texts)

```

**ê²°ê³¼**:

```
{'text': 'ë‹¤ì‹œ ë³´ê³  ì‹¶ì€ ì˜í™”', 'label': 'positive', 'confidence': 0.93}
{'text': 'ë³„ë¡œì—ìš”', 'label': 'negative', 'confidence': 0.85}
```


### 6.5 ëª¨ë¸ ê´€ë¦¬

í•™ìŠµ ì™„ë£Œ í›„ í„°ë¯¸ë„ì— ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë¸ ê´€ë¦¬ ê´€ë ¨ ë©”ì‹œì§€ì— ë”°ë¼ CLIì—ì„œ ìˆ«ì ë˜ëŠ” `y/n`ì„ ì…ë ¥í•˜ì—¬ ëª¨ë¸ì„ ê´€ë¦¬.

- **ëª¨ë¸ ë“±ë¡**: ëª¨ë¸ì„ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í• ì§€ ì—¬ë¶€ ì„ íƒ
- **ëª¨ë¸ ë‹¨ê³„ ì„¤ì •**: ëª¨ë¸ì˜ ë‹¨ê³„(stage)ë¥¼ ì„¤ì • (ì˜ˆ: None, Staging, Production)

### 6.6 ê²°ê³¼ í™•ì¸

- **MLflow UI**: ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í—˜ ê²°ê³¼, ë©”íŠ¸ë¦­, íŒŒë¼ë¯¸í„° ë° ì•„í‹°íŒ©íŠ¸ë¥¼ í™•ì¸.
- **í´ë” êµ¬ì¡°**:
    - `mlruns/` í´ë”ì— ì‹¤í–‰(run) ê´€ë ¨ ë¡œê·¸ì™€ ë©”íŠ¸ë¦­ì´ ì €ì¥.
    - `exp id / exp id / artifacts /` í´ë”ì— ëª¨ë¸ íŒŒì¼ ë“± ì•„í‹°íŒ©íŠ¸ê°€ ì €ì¥.
    - `config/model_info.json` íŒŒì¼ì—ì„œ ë“±ë¡ëœ ëª¨ë¸ì˜ ë‹¨ê³„(stage)ë¥¼ í™•ì¸.

### 6.7 Streamlit ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰

```bash
streamlit run app.py
```

- ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ëª¨ë¸ í…ŒìŠ¤íŠ¸


### 6.8 Docker & Airflow Setup
- init-scripts/init.sh íŒŒì¼ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ì´ˆê¸° ì„¤ì • íŒŒì¼
- Airflow, Slack webhook ì—°ê²° ê³„ì • ìë™ ìƒì„±

#### ğŸ“ init-scripts
- **init.sh**: ì´ˆê¸° ì„¤ì • íŒŒì¼
#### ğŸ“ 
- **Dockerfile**: Docker ì»¨í…Œì´ë„ˆ ì„¤ì • íŒŒì¼
- **docker-compose.yml**: Docker ì»¨í…Œì´ë„ˆ ê´€ë¦¬ íŒŒì¼

#### ì‚¬ìš©ë²• ë° ëª…ë ¹ì–´

Airflowë¥¼ Dockerë¡œ ì„¤ì •í•˜ë ¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰:

```bash
docker-compose up --build -d

```

#### Slack Webhook ì„¤ì •

Airflowì—ì„œ Slack Webhookì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ì •ë³´ë¥¼ `.env` íŒŒì¼ì— ì €ì¥:

 `.env` íŒŒì¼ ì˜ˆì‹œ

```
env
ì½”ë“œ ë³µì‚¬
# Slack Webhook Token ì„¤ì •
SLACK_WEBHOOK_TOKEN=PUT YOUR SLACK TOKEN

# Airflow ì„¤ì •
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////usr/local/ml4/airflow.db
AIRFLOW__PROVIDERS__SLACK__WEBHOOK_CONN_ID=slack_webhook

```

ë§Œì•½ ìë™ ì„¤ì •ì´ ì•ˆë˜ëŠ” ê²½ìš°, Slack Webhook ì—°ê²°ì„ ìœ„í•´ Airflowì˜ Connection IDë¥¼ ì•„ë˜ì™€ ê°™ì´ ì„¤ì •

- **Connection ID**: `slack_webhook`
- **Token**: `.env` íŒŒì¼ì— ì„¤ì •ëœ `SLACK_WEBHOOK_TOKEN` ê°’ ì‚¬ìš©

---

#### Airflow ê³„ì • ìë™ ìƒì„±

Airflow ì´ˆê¸° ì„¤ì • ì‹œ ë‹¤ìŒ ê¸°ë³¸ ê³„ì •ì´ ìë™ìœ¼ë¡œ ìƒì„±:

- **ID**: `admin`
- **Password**: `admin`
  
#### ì¶”ê°€ ì°¸ê³  ì‚¬í•­

- `docker-compose.yml` íŒŒì¼ì´ ì œëŒ€ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.
- Airflowë¥¼ ì‹¤í–‰í•œ í›„ ì›¹ UIì—ì„œ Slack Webhook Connection ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸.

---
### 6.9 CrawlerService

Python ê¸°ë°˜ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ê²€ìƒ‰ì–´(Query)ë¥¼ ì…ë ¥ë°›ì•„ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ JSON ë˜ëŠ” CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

---

#### ì£¼ìš” ê¸°ëŠ¥

- **Scrapy ê¸°ë°˜ í¬ë¡¤ë§**: Scrapyì™€ Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
- **ê²°ê³¼ ì €ì¥**: í¬ë¡¤ë§ ê²°ê³¼ë¥¼ JSON ë° CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥.
- **ì‚¬ìš© í¸ì˜ì„±**: Python í•¨ìˆ˜ í˜¸ì¶œ ë˜ëŠ” ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‹¤í–‰ ê°€ëŠ¥.

---

#### ì„¤ì¹˜ ë°©ë²•

1. ì €ì¥ì†Œ í´ë¡ 
   git clone <repository_url>
   cd CrawlerService

2. ê°€ìƒí™˜ê²½ ì„¤ì •
   python3.12 -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate

3. ì˜ì¡´ì„± ì„¤ì¹˜
   pip install -r requirements.txt

---

#### ì‹¤í–‰ ë°©ë²•

1. Scrapy ëª…ë ¹ì–´ë¡œ ì‹¤í–‰
   ê²€ìƒ‰ì–´(Query)ë¥¼ ì…ë ¥í•˜ì—¬ í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
   [ì˜ˆì‹œ]
   ```bash
   scrapy crawl naver_blog_spider
   scrapy crawl naver_blog_spider -a verbose=True
   scrapy crawl naver_blog_spider -a verbose=True -o output/naver_blog_crawling.csv
   scrapy crawl naver_blog_spider -a verbose=True -a query=ìŠ¤ìœ„ìŠ¤,ë…ì¼
   scrapy crawl naver_blog_spider -a verbose=True -a query=ìŠ¤ìœ„ìŠ¤,ë…ì¼ -a max_results=4
   scrapy crawl naver_blog_spider -a verbose=True -a query=ì´íƒˆë¦¬ì•„ -a max_results=2
   scrapy crawl naver_blog_spider -a verbose=True -a query=ì¼ë³¸,ì¤‘êµ­,ë² íŠ¸ë‚¨ -a max_results=5
   scrapy crawl naver_blog_spider -a verbose=True -a query=ì¼ë³¸,ì¤‘êµ­,ë² íŠ¸ë‚¨ -a max_results=5 -o output/test001.csv
   ```
   [ERROR]
   ì•„ë˜ì™€ ê°™ì€ ê²½ìš° errorê°€ ë°œìƒí•©ë‹ˆë‹¤.
   ```bash
   # ######################################################################
   crawl: error: running 'scrapy crawl' with more than one spider is not supported
   # ######################################################################
   scrapy crawl naver_blog_spider -a verbose=True -t csv  [crawl: error]
   scrapy crawl naver_blog_spider -a verbose=True -a query= ìŠ¤ìœ„ìŠ¤,ë…ì¼  [crawl: error]
   # ######################################################################
   ```
2. Python ì½”ë“œë¡œ ì‹¤í–‰
   crawler_service.pyì˜ run_crawler í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤:

   [test_crawler.py]
   ```bash
   from CrawlerService.crawler_service import run_crawler
   ```
   #### í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
   ```bash
   output_filename = "naver_blog_crawling"
   result = run_crawler(query="ì¼ë³¸ ë„ì¿„,í•œêµ­ ì„œìš¸", verbose=True, max_results=4, output_filename=output_filename)
   print(f"í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ (CSV file): output/{output_filename}.csv")
   print(f"í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ (JSON file): output/{output_filename}.json")
   ```
---

#### ê°œë°œ ë° ë””ë²„ê¹…

1. ì˜ì¡´ì„± ë¶„ì„
   pipdeptreeë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì íŠ¸ ì˜ì¡´ì„±ì„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
   pip install pipdeptree
   pipdeptree

2. ë¡œê¹…
   í¬ë¡¤ë§ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ëª¨ë“  ë¡œê·¸ëŠ” logs/ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.

---

##### í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°

í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```bash
CrawlerService
â”œâ”€â”€ CrawlerService
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ crawler_service.py
â”‚Â Â  â”œâ”€â”€ items.py
â”‚Â Â  â”œâ”€â”€ pipelines.py
â”‚Â Â  â”œâ”€â”€ settings.py
â”‚Â Â  â”œâ”€â”€ setup.py
â”‚Â Â  â””â”€â”€ spiders
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â””â”€â”€ naver_blog_spider.py
â”œâ”€â”€ README.md
â”œâ”€â”€ app
â”‚Â Â  â””â”€â”€ main.py
â”œâ”€â”€ logs
â”œâ”€â”€ output
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ test_crawler.py
â”œâ”€â”€ .gitignore
â””â”€â”€ venv
```

---

## 7. Result ì£¼ìš” ì„±ê³¼ ë° ê°œì„  ë°©í–¥
### ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ ì„œë¹„ìŠ¤ ë°ëª¨ ì‹œì—°
- ê°ì„± ì±—ë´‡ê³¼ ëŒ€í™” ë¶„ì„ ê¸°ëŠ¥ ë“± ì¶”ê°€
![ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ ì„œë¹„ìŠ¤ ë°ëª¨](https://github.com/UpstageAILab5/upstageailab-ml-pjt-ml_p4/blob/main/assets/images/demo.png)

### 7.1 ìµœì¢… ì„±ê³¼

- **ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ ì„œë¹„ìŠ¤ êµ¬ì¶•**:
    - í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ ê¸ì •/ë¶€ì • ë¶„ë¥˜ ëª¨ë¸ ê°œë°œ
    - ì •ì œë˜ì§€ ì•Šì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°ì„± ë¶„ë¥˜ì—ì„œ ë†’ì€ ì •í™•ë„ì™€ ì•ˆì •ì„± ë‹¬ì„±
- **MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**:
    - ëª¨ë¸, ë°ì´í„° ê´€ë¦¬ ë° MLOps ì¸í”„ë¼ ì „ë°˜ ì´í•´ ë° êµ¬í˜„

### 7.2 ë„ì „ ê³¼ì œ ë° í•´ê²° ë°©ì•ˆ

- **ë°ì´í„°ì…‹**:
    - **ë¬¸ì œ**: ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° ëª¨ë¸ í•™ìŠµì˜ ì–´ë ¤ì›€
    - **í•´ê²°**: ëª©í‘œ ë°ì´í„° íƒ€ì…ê³¼ ìœ ì‚¬í•œ íŠ¹ì„±ì„ ê°€ì§„ ëŒ€ê·œëª¨ ë ˆì´ë¸” ë°ì´í„°ì…‹ì„ ì´ìš©, ê¸°ë³¸ ëª¨ë¸ì„ í•™ìŠµ
- **MLOps í†µí•©**:
    - **ë¬¸ì œ**: ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ë° ë°°í¬ì˜ ì›í™œí•œ ì—°ê³„
    - **í•´ê²°**: MLflowë¥¼ í™œìš©í•œ ì‹¤í—˜ ì¶”ì  ë° ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬í˜„
- **ëª¨ë¸ ë°°í¬**:
    - **ë¬¸ì œ**: ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ìœ„í•œ ë‚®ì€ ì§€ì—° ì‹œê°„ í™•ë³´
    - **í•´ê²°**: FastAPIì™€ ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ëª¨ë¸ ì„œë¹™ ìµœì í™”

### 7.3 í–¥í›„ ê°œì„  ë°©í–¥
1. **Airflow ìë™í™” í†µí•©**: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ, ë°°í¬ ìë™í™”
2. **ë‹¤ì¤‘ ê°ì • ë¶„ë¥˜ í™•ì¥**: ì¤‘ë¦½ ë° ë³µí•© ê°ì •ì„ ì¶”ê°€ë¡œ ì˜ˆì¸¡
3. **ëª¨ë¸ ì¼ë°˜í™” í–¥ìƒ**: ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ì‚¬ìš©
4. **í”„ë¡ íŠ¸ì—”ë“œ ê°œì„ **: ì‚¬ìš©ì ê²½í—˜ ìµœì í™”
5. **ë‹¤ì¤‘ ìœ ì € ì •ë³´ ê´€ë¦¬**: ë‹¤ì–‘í•œ ìœ ì € ì •ë³´ ê´€ë¦¬ ë° ëª¨ë¸ í…ŒìŠ¤íŠ¸


### 7.3 í”„ë ˆì  í…Œì´ì…˜ ë° íšŒì˜ë¡
- **Report**
  - [Upstage AI Lab Fast-Up Report](https://www.notion.so/Fast-Up-Team-Report-1-c8476dbc79234d85b275fc532dfbbbdd?pvs=4)
- **Presentation**
  - [pdf](https://github.com/UpstageAILab5/upstageailab-ml-pjt-ml_p4/blob/main/assets/docs/%5B%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4%5D-Upstage-AI-Lab-5%EA%B8%B0_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-ML4.pdf)
- **Meeting Log**
  - [íšŒê³  ë° ë¯¸íŒ… ë¡œê·¸](https://www.notion.so/a6667a35aec348a2bfbba76bfcdd6343?v=2c6a809bc92b4dd4a77247c99caba688&pvs=4)
  - [í”¼ì–´ ì„¸ì…˜ ë° ë©˜í† ë§](https://www.notion.so/37086a60fda642efb175576e0887fd7c?v=e22cf0fd881a481c8b0c6dab27dfac28&pvs=4)
---

## 8. ì°¸ê³  ìë£Œ
### 8.1 ë°ì´í„° ìˆ˜ì§‘
- **Selenium ë¬¸ì„œ**: [Selenium](https://selenium-python.readthedocs.io/)
- **Scrapy ë¬¸ì„œ**: [Scrapy](https://docs.scrapy.org/en/latest/)
### 8.2 ë°ì´í„°ì…‹
- **NSMC ë°ì´í„°ì…‹**: [GitHub - e9t/nsmc](https://github.com/e9t/nsmc)
### 8.3 ëª¨ë¸
- **Hugging Face**: [Hugging Face](https://huggingface.co/)
- **Kc-BERT ëª¨ë¸**: [GitHub - Beomi/KcBERT](https://github.com/Beomi/KcBERT)
- **KC-ELECTRA ëª¨ë¸**: [Hugging Face - beomi/KcELECTRA-base](https://huggingface.co/beomi/KcELECTRA-base)
### 8.4 MLOps
- **MLflow ë¬¸ì„œ**: [MLflow](https://mlflow.org/docs/latest/index.html)
### 8.4 í”„ë¡ íŠ¸ì—”ë“œ
- **Streamlit ë¬¸ì„œ**: [Streamlit](https://docs.streamlit.io/)
### 8.5 ë°±ì—”ë“œ  
- **FastAPI ë¬¸ì„œ**: [FastAPI](https://fastapi.tiangolo.com/)
### 8.6 ë°°í¬
- **Airflow ë¬¸ì„œ**: [Airflow](https://airflow.apache.org/)
