from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import pandas as pd
import numpy as np
from slack_sdk import WebClient
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Slack ì„¤ì •
SLACK_TOKEN = os.getenv("SLACK_TOKEN")
SLACK_CHANNEL = "#model-training"  # ì‹¤ì œ ì±„ë„ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìš”

def split_dataset():
    """ë°ì´í„°ì…‹ì„ nê°œë¡œ ë¶„í• í•˜ê³  ê°ê° ì €ì¥"""
    # ë°ì´í„° ë¡œë“œ (ì˜ˆ: NSMC ë°ì´í„°ì…‹)
    data = pd.read_csv("/path/to/nsmc_dataset.csv")  # ì‹¤ì œ ë°ì´í„° ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”
    
    # ë°ì´í„°ë¥¼ nê°œë¡œ ë¶„í• 
    n_splits = 5  # ì›í•˜ëŠ” ë¶„í•  ìˆ˜ë¡œ ìˆ˜ì •
    split_size = len(data) // n_splits
    
    for i in range(n_splits):
        start_idx = i * split_size
        end_idx = start_idx + split_size if i < n_splits - 1 else len(data)
        
        split_data = data.iloc[start_idx:end_idx]
        split_data.to_csv(f"/path/to/splits/split_{i}.csv", index=False)
    
    return n_splits

def send_slack_message(message, channel=SLACK_CHANNEL):
    """Slack ë©”ì‹œì§€ ì „ì†¡"""
    client = WebClient(token=SLACK_TOKEN)
    try:
        response = client.chat_postMessage(
            channel=channel,
            text=message
        )
        return response
    except Exception as e:
        print(f"Error sending slack message: {str(e)}")
        return None

def train_and_notify(split_index, **context):
    """ëª¨ë¸ í•™ìŠµ ë° ê²°ê³¼ ì•Œë¦¼"""
    # í•™ìŠµ ì‹œì‘ ì•Œë¦¼
    start_message = f"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Split {split_index})"
    send_slack_message(start_message)
    
    try:
        # ëª¨ë¸ í•™ìŠµ
        config_path = "config/config.yaml"
        dataset_path = f"/path/to/splits/split_{split_index}.csv"
        
        result = train_model(
            config_path=config_path,
            dataset_name=dataset_path,
            interactive=False
        )
        
        # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
        metrics = result['metrics']
        message = f"""
        âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (Split {split_index})
        
        ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:
        - Validation Accuracy: {metrics['val_accuracy']:.4f}
        - Validation F1 Score: {metrics['val_f1']:.4f}
        - Validation Precision: {metrics['val_precision']:.4f}
        - Validation Recall: {metrics['val_recall']:.4f}
        
        ğŸ” Run ID: {result['run_id']}
        """
        
    except Exception as e:
        message = f"""
        âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ (Split {split_index})
        ì˜¤ë¥˜: {str(e)}
        """
    
    # ê²°ê³¼ ì•Œë¦¼
    send_slack_message(message)

# DAG ì •ì˜
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email': ['your-email@example.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'model_training_pipeline',
    default_args=default_args,
    description='ì£¼ê¸°ì  ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸',
    schedule_interval='0 2 * * *',  # ë§¤ì¼ ì˜¤ì „ 2ì‹œì— ì‹¤í–‰
    catchup=False
)

# ë°ì´í„°ì…‹ ë¶„í•  íƒœìŠ¤í¬
split_task = PythonOperator(
    task_id='split_dataset',
    python_callable=split_dataset,
    dag=dag,
)

# ê° ë¶„í• ì— ëŒ€í•œ í•™ìŠµ íƒœìŠ¤í¬ ìƒì„±
training_tasks = []
for i in range(5):  # n_splitsì™€ ë™ì¼í•œ ìˆ˜ë¡œ ì„¤ì •
    train_task = PythonOperator(
        task_id=f'train_model_split_{i}',
        python_callable=train_and_notify,
        op_kwargs={'split_index': i},
        dag=dag,
    )
    training_tasks.append(train_task)

# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì •
split_task >> training_tasks 